# -*- coding: utf-8 -*-
"""Rice Type Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oA-XxtKKFHjVh48B6uss9h38TwD3-6Su
"""

!pip install opendatasets --quiet
import opendatasets as od
od.download("https://www.kaggle.com/datasets/mssmartypants/rice-type-classification")

import torch
import torch.nn as nn
from torch.optim import Adam
from torch.utils.data import Dataset, DataLoader
from torchsummary import summary
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device)

data_df = pd.read_csv('/content/rice-type-classification/riceClassification.csv')
data_df.head()

if 'id' in data_df.columns:
    data_df.drop(['id'], axis=1, inplace=True)
else:
    print("Column 'id' not found.")

data_df.dropna(inplace=True)
print(data_df.shape)

data_df.head()

print(data_df['Class'].unique())

print(data_df['Class'].value_counts())

original_df = data_df.copy()

for column in data_df.columns:
  data_df[column] = data_df[column] / data_df[column].abs().max()

data_df.head()

X = np.array(data_df.iloc[:,:-1])
Y = np.array(data_df.iloc[:,-1])

X_train, X_test, Y_train, Y_test = train_test_split(X , Y, test_size = 0.3)

X_test, X_val, Y_test, Y_val = train_test_split(X_test , Y_test, test_size = 0.5)

print(X_train.shape)
print(X_test.shape)
print(X_val.shape)

class dataset(Dataset):
  def __init__(self,X,Y):
     self.X=torch.tensor(X, dtype=torch.float32).to(device)
     self.Y=torch.tensor(Y, dtype=torch.float32).to(device)

  def __len__(self):
    return len(self.X)

  def __getitem__(self, index):
    return self.X[index], self.Y[index]

training_data = dataset(X_train,Y_train)
testing_data = dataset(X_test,Y_test)
validation_data = dataset(X_val,Y_val)

train_dataloader = DataLoader(training_data, batch_size=8, shuffle=True)
test_dataloader = DataLoader(testing_data, batch_size=8, shuffle=True)
validation_dataloader = DataLoader(validation_data, batch_size=8, shuffle=True)

for x,y in train_dataloader:
  print(x)
  print('============================================')
  print(y)
  break

HIDDEN_NEURONS = 10
class MyModel(nn.Module):
  def __init__(self):
    super(MyModel,self).__init__()
    self.input_layer = nn.Linear(X.shape[1], HIDDEN_NEURONS)
    self.linear = nn.Linear(HIDDEN_NEURONS,1)
    self.sigmoid = nn.Sigmoid()

  def forward(self,x):
    x = self.input_layer(x)
    x = self.linear(x)
    x = self.sigmoid(x)
    return x

model = MyModel().to(device)

summary(model, (X.shape[1],))

criterion = nn.BCELoss()
optimizer = Adam(model.parameters(), lr =1e-3)

total_loss_train_plot = []
total_loss_validation_plot = []
total_acc_train_plot = []
total_acc_validation_plot = []

epochs = 10
for epoch in range(epochs):
  total_acc_train = 0
  total_loss_train = 0
  total_acc_val = 0
  total_loss_val = 0

  for data in train_dataloader:
    inputs, labels = data

    prediction = model(inputs).squeeze(1)
    batch_loss=criterion(prediction, labels)

    total_loss_train += batch_loss.item()

    acc = ((prediction).round() == labels).sum().item()
    total_acc_train += acc

    batch_loss.backward()
    optimizer.step()
    optimizer.zero_grad()

  with torch.no_grad():
    for data in validation_dataloader:
      inputs, labels = data
      prediction = model(inputs).squeeze(1)
      batch_loss = criterion(prediction, labels)
      total_loss_val += batch_loss.item()

      acc = ((prediction).round() == labels).sum().item()
      total_acc_val += acc
  total_loss_train_plot.append(round(total_loss_train/1000, 4))
  total_loss_validation_plot.append(round(total_loss_val/1000, 4))
  total_acc_train_plot.append(round(total_acc_train/training_data.__len__() * 100 , 4))
  total_acc_validation_plot.append(round(total_acc_val/validation_data.__len__() * 100, 4))
  print(f'''Epoch no. {epoch+1} Train loss : {round(total_loss_train/1000, 4)} Train Accuracy {round(total_acc_train/training_data.__len__() * 100 , 4)}
        Validation Loss : {round(total_loss_val/1000, 4)} Validation Accuracy{round(total_acc_val/validation_data.__len__() * 100, 4)}''')
  print("="*25)

with torch.no_grad():
  total_loss_test = 0
  total_acc_test = 0
  for data in test_dataloader:
    inputs, labels = data
    prediction = model(inputs).squeeze(1)

    batch_loss_test= criterion(prediction,labels).item()
    total_loss_test += batch_loss_test
    acc = ((prediction).round() == labels).sum().item()
    total_acc_test += acc

  print("Accuracy : ",round(total_acc_test/testing_data.__len__() * 100, 4))

flg, axs = plt.subplots(nrows=1 , ncols=2, figsize= (15,5))

axs[0].plot(total_loss_train_plot, label='Training Loss')
axs[0].plot(total_loss_validation_plot, label='Validation Loss')
axs[0].set_title("Training and Validation loss over epochs")
axs[0].set_xlabel('Epochs')
axs[0].set_xlabel('Loss')
axs[0].set_ylim([0,2])
axs[0].legend()


axs[1].plot(total_acc_train_plot, label='Training Accuracy')
axs[1].plot(total_acc_validation_plot, label='Validation Accuracy')
axs[1].set_title("Training and Validation accuracy over epochs")
axs[1].set_xlabel('Epochs')
axs[1].set_xlabel('Accuracy')
axs[1].set_ylim([0,100])
axs[1].legend()

plt.show()

original_df.columns

original_df.head()

Area = 2345/original_df['Area'].abs().max()

MajorAxisLength = 82/original_df['MajorAxisLength'].abs().max()

MinorAxisLength = 43/original_df['MinorAxisLength'].abs().max()

Eccentricity = 0.87/original_df['Eccentricity'].abs().max()

ConvexArea = 3222/original_df['ConvexArea'].abs().max()

EquivDiameter = 76/original_df['EquivDiameter'].abs().max()

Extent = 0.77/original_df['Extent'].abs().max()

Perimeter = 200/original_df['Perimeter'].abs().max()

Roundness = 0.43/original_df['Roundness'].abs().max()

AspectRation = 1.1/original_df['AspectRation'].abs().max()

my_prediction = model(torch.tensor([Area, MajorAxisLength, MinorAxisLength, Eccentricity,
       ConvexArea, EquivDiameter,Extent,Perimeter, Roundness,
       AspectRation], dtype=torch.float32).to(device))

round(my_prediction.item())